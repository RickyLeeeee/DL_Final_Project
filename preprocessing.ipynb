{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 針對 刑法320竊盜罪 且刑責與刑期都只有一項 (避免多人、多罪名)\n",
    "* X = 犯罪事實 (起訴書)\n",
    "* Y = 判決 (裁判書)\n",
    "* 對 X 斷詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7fec6ec4e550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7fec6ec4e550>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7fec6ec4eda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7fec6ec4eda0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7fec6ec4ef98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7fec6ec4ef98>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7fec6ec4efd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7fec6ec4efd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fec6eefe3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fec6eefe3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "CPU times: user 1h 53min 30s, sys: 12min 26s, total: 2h 5min 57s\n",
      "Wall time: 36min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import json, pickle, re, os\n",
    "import tensorflow as tf\n",
    "from ckiptagger import WS\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR) # ignore tensorflow warning\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0' # to use gpu\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config) # let keras use only required VRAM\n",
    "ws = WS('./ckip/data')\n",
    "\n",
    "with open('facts.json', 'r') as f:\n",
    "    facts = json.load(f)\n",
    "with open('maintext_parsed.json', 'r') as f:\n",
    "    maintext = json.load(f)\n",
    "with open('./pkl/criminal_320.pkl', 'rb') as f:\n",
    "    criminal_320 = pickle.load(f)\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "X_seg = []\n",
    "\n",
    "### select the data\n",
    "for file, key_list in criminal_320.items():\n",
    "    for key in key_list:\n",
    "        if facts[key] == None:\n",
    "            continue\n",
    "        try: label = maintext[key]['labels']\n",
    "        except: continue\n",
    "        if len(label) == 1:\n",
    "            label = label[0]\n",
    "\n",
    "            fact = re.sub('\\s', '', str(facts[key]))\n",
    "            if (label == '有期徒刑' and len(maintext[key]['imprisonment']) == 1) or \\\n",
    "            (label == '拘役' and len(maintext[key]['short_imprisonment']) == 1) or \\\n",
    "            label == '罰金' or label == '無罪':\n",
    "                X.append(fact)\n",
    "                Y.append(label)\n",
    "\n",
    "### segmentation\n",
    "for i, fact in enumerate(X):\n",
    "    try:\n",
    "        fact = re.sub('\\s', '', fact)\n",
    "        X_seg.append(' '.join(ws([fact])[0]))\n",
    "    except:continue\n",
    "        \n",
    "with open('./pkl/X.pkl', 'wb') as f:\n",
    "    pickle.dump(X, f)\n",
    "with open('./pkl/Y.pkl', 'wb') as f:\n",
    "    pickle.dump(Y, f)\n",
    "with open('./pkl/X_seg.pkl', 'wb') as f:\n",
    "    pickle.dump(X_seg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totol 12298\n",
      "拘役 6437\n",
      "有期徒刑 3617\n",
      "罰金 1996\n",
      "無罪 248\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pickle\n",
    "with open('./pkl/Y.pkl', 'rb') as f:\n",
    "    Y = pickle.load(f)\n",
    "print('Totol', len(Y))\n",
    "\n",
    "z = Counter(Y)\n",
    "for i in list(z.most_common()):\n",
    "    print(i[0], i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 建立 embedding_matrix for keras, word_idx for padding\n",
    "* X : 將斷詞過的文本轉換成由數字組成的相同長度序列，每個數字代表一組詞彙\n",
    "* Y_onehot : 將各種 判決 轉換成 數字 再轉換成 one-hot encoding\n",
    "* 分割資料\n",
    "* y_test_act : 把 one-hot 再轉回數字，最後的 confusion matrix 可以用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_seq_len(X_seg, percentage):\n",
    "    word_count = Counter([len(x.split(' ')) for x in X_seg])\n",
    "    sort_count = sorted(word_count.items(), key=lambda kv: kv[0])\n",
    "    max_len = 0\n",
    "    for k, v in sort_count:\n",
    "        max_len += v\n",
    "        if max_len/len(X_seg) > percentage:\n",
    "            return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "from collections import Counter\n",
    "with open('./pkl/X_seg.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "    \n",
    "max_seq_len(X, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.72 s, sys: 32.5 s, total: 38.2 s\n",
      "Wall time: 38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open('./pkl/X_seg.pkl', 'rb') as f:\n",
    "    X_seg = pickle.load(f)\n",
    "with open('./pkl/Y.pkl', 'rb') as f:\n",
    "    Y = pickle.load(f)\n",
    "wv_model = Word2Vec.load('./data/fact_w2v.model')\n",
    "max_sequence_len = max_seq_len(X_seg, 0.9)\n",
    "\n",
    "word_idx = {\"_PAD\": 0}\n",
    "vocab_list = [(k, wv_model.wv[k]) for k, v in wv_model.wv.vocab.items()]\n",
    "embedding_matrix = np.zeros((len(wv_model.wv.vocab) + 1, wv_model.vector_size))\n",
    "for i, word in enumerate(vocab_list):\n",
    "    word_idx[word[0]] = i+1\n",
    "    embedding_matrix[i+1] = word[1]\n",
    "\n",
    "X = [[word_idx.get(w, 0) for w in doc.split(' ')] for doc in X_seg]\n",
    "X = pad_sequences(X, maxlen=max_sequence_len)\n",
    "\n",
    "le = LabelEncoder()\n",
    "Y_le = le.fit_transform(Y)\n",
    "Y_onehot = to_categorical(Y_le)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_onehot, test_size=0.3, shuffle=True, random_state=5566)\n",
    "y_test_act = [np.where(r==1)[0][0] for r in y_test]\n",
    "y_test_act = np.array(y_test_act)\n",
    "\n",
    "with open('./pkl/x_train.pkl', 'wb') as f:\n",
    "    pickle.dump(x_train, f)\n",
    "with open('./pkl/y_train.pkl', 'wb') as f:\n",
    "    pickle.dump(y_train, f)\n",
    "with open('./pkl/x_test.pkl', 'wb') as f:\n",
    "    pickle.dump(x_test, f)\n",
    "with open('./pkl/y_test.pkl', 'wb') as f:\n",
    "    pickle.dump(y_test, f)\n",
    "with open('./pkl/y_test_act.pkl', 'wb') as f:\n",
    "    pickle.dump(y_test_act, f)\n",
    "with open('./pkl/embedding_matrix.pkl', 'wb') as f:\n",
    "    pickle.dump(embedding_matrix, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
